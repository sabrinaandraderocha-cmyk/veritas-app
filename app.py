import os
import re
import time
import streamlit as st

from veritas_utils import (
    extract_text_from_txt_bytes,
    extract_text_from_docx_bytes,
    extract_text_from_pdf_bytes,
    compute_matches,
    highlight_text,
)
from veritas_report import generate_pdf_report

APP_TITLE = "Veritas"

DISCL = (
    "O Veritas realiza an√°lise automatizada de similaridade textual. "
    "O resultado n√£o configura, por si s√≥, ju√≠zo definitivo sobre pl√°gio acad√™mico, "
    "o qual depende de avalia√ß√£o contextual e humana (cita√ß√µes, par√°frases, dom√≠nio p√∫blico, etc.)."
)

ETHICAL_NOTE = (
    "‚ö†Ô∏è Similaridade n√£o √©, por si s√≥, falta √©tica. "
    "A escrita acad√™mica √© dial√≥gica: trechos conceituais, metodologia, cita√ß√µes e f√≥rmulas recorrentes "
    "podem elevar a correspond√™ncia. Use o relat√≥rio como apoio de revis√£o, n√£o como veredito."
)

# ----------------------------
# Helpers
# ----------------------------
def _read_any(uploaded_file) -> str:
    name = uploaded_file.name.lower()
    b = uploaded_file.getvalue()
    if name.endswith(".txt"):
        return extract_text_from_txt_bytes(b)
    if name.endswith(".docx"):
        return extract_text_from_docx_bytes(b)
    if name.endswith(".pdf"):
        return extract_text_from_pdf_bytes(b)
    return extract_text_from_txt_bytes(b)


def _safe_words_count(text: str) -> int:
    return len(re.findall(r"\S+", text or ""))


def _band(global_sim: float):
    """
    Faixas interpretativas (N√ÉO punitivas).
    Ajuste livremente depois.
    """
    if global_sim < 0.15:
        return "üü¢ Similaridade esperada (baixa)", (
            "Em geral, indica boa autonomia textual. Ainda assim, revise se as cita√ß√µes est√£o completas."
        )
    if global_sim < 0.30:
        return "üü° Aten√ß√£o editorial (moderada)", (
            "Pode refletir trechos conceituais comuns, metodologia parecida ou par√°frases pr√≥ximas. "
            "Vale revisar as se√ß√µes sinalizadas e checar cita√ß√µes/par√°frases."
        )
    return "üü† Revis√£o cuidadosa (elevada)", (
        "N√£o √© acusa√ß√£o. Indica que h√° bastante sobreposi√ß√£o com sua biblioteca. "
        "Reveja trechos sinalizados, garanta cita√ß√µes corretas e aumente elabora√ß√£o autoral."
    )


def _chunk_type_heuristic(chunk: str) -> str:
    """
    Heur√≠stica simples para rotular o tipo de trecho (sem prometer perfei√ß√£o).
    """
    c = (chunk or "").strip()

    # cita√ß√£o direta prov√°vel
    if "‚Äú" in c or "‚Äù" in c or '"' in c or "''" in c or "‚Äò‚Äò" in c or "‚Äô" in c:
        return "üìå Cita√ß√£o direta prov√°vel"

    # autor-data prov√°vel: (SOBRENOME, 2020) / (Autor, 2020)
    if re.search(r"\([A-Za-z√Ä-√ø][A-Za-z√Ä-√ø\s\-]+,\s*\d{4}[a-z]?\)", c):
        return "üìö Cita√ß√£o autor-data prov√°vel"

    lower = c.lower()

    # metodologia
    metod_terms = [
        "metodologia", "m√©todo", "amostra", "participantes", "procedimento",
        "instrumento", "coleta", "an√°lise de dados", "an√°lise estat√≠stica",
        "m√©todos", "material e m√©todos", "desenho do estudo"
    ]
    if any(t in lower for t in metod_terms):
        return "üß™ Metodologia / Procedimentos (similaridade comum)"

    # te√≥rico/conceitual
    theory_terms = [
        "conceito", "define-se", "defini√ß√£o", "segundo", "de acordo com",
        "compreende-se", "refere-se", "pressup√µe", "no√ß√£o", "teoria"
    ]
    if any(t in lower for t in theory_terms):
        return "üìñ Conceitual / Te√≥rico (similaridade comum)"

    return "‚úçÔ∏è Argumentativo / Autoral (revise com aten√ß√£o)"


def _likely_bibliographic(chunk: str) -> bool:
    lower = (chunk or "").lower()
    bib_markers = ["refer√™ncias", "bibliografia", "apud", "et al.", "doi:", "http://", "https://"]
    return any(m in lower for m in bib_markers)


def _doc_summary(matches):
    """
    Agrupa correspond√™ncias por documento fonte, para facilitar leitura.
    """
    by_doc = {}
    for m in matches or []:
        by_doc.setdefault(m.source_doc, []).append(m)
    # ordena por maior score m√©dio
    items = []
    for doc, ms in by_doc.items():
        avg = sum(x.score for x in ms) / max(1, len(ms))
        items.append((doc, avg, len(ms)))
    items.sort(key=lambda x: x[1], reverse=True)
    return items


def _init_state():
    if "library" not in st.session_state:
        st.session_state["library"] = {}  # name -> text

    # metadados simples (tags/exclus√µes) por documento
    if "library_meta" not in st.session_state:
        st.session_state["library_meta"] = {}  # name -> dict(tags, category, exclude)

    if "last_result" not in st.session_state:
        st.session_state["last_result"] = None

    if "params" not in st.session_state:
        st.session_state["params"] = {
            "chunk_words": 60,
            "stride_words": 20,
            "threshold": 0.75,
            "top_k_per_chunk": 1,
            "exclude_marked": True,
        }

    if "ui" not in st.session_state:
        st.session_state["ui"] = {
            "max_matches_show": 20,
            "show_review_mode": True,
            "show_doc_summary": True,
            "show_chunk_labels": True,
        }


# ----------------------------
# UI
# ----------------------------
st.set_page_config(page_title=APP_TITLE, layout="wide")
_init_state()

st.title(f"üèõÔ∏è {APP_TITLE}")
st.caption("An√°lise de similaridade e integridade acad√™mica")

tabs = st.tabs(["Nova an√°lise", "Biblioteca", "Configura√ß√µes"])

# =========================================================
# TAB 1: Nova an√°lise
# =========================================================
with tabs[0]:
    col1, col2 = st.columns([1.15, 0.85], gap="large")

    with col1:
        st.subheader("Texto para an√°lise")
        mode = st.radio(
            "Como voc√™ quer enviar o texto?",
            ["Colar texto", "Enviar arquivo"],
            horizontal=True
        )

        query_name = "Texto colado"
        query_text = ""

        if mode == "Colar texto":
            query_text = st.text_area(
                "Cole aqui o texto do trabalho/artigo:",
                height=260,
                placeholder="Cole seu texto aqui..."
            )
        else:
            up = st.file_uploader("Envie um arquivo (.docx, .pdf, .txt)", type=["docx", "pdf", "txt"])
            if up is not None:
                query_name = up.name
                try:
                    query_text = _read_any(up)
                except Exception as e:
                    st.error(f"N√£o consegui ler o arquivo. Erro: {e}")

        st.divider()

        st.subheader("Rodar an√°lise")

        if not st.session_state["library"]:
            st.warning("Sua biblioteca est√° vazia. V√° na aba **Biblioteca** e fa√ßa upload de documentos para comparar.")

        run = st.button(
            "üîé Analisar",
            type="primary",
            use_container_width=True,
            disabled=(not query_text or not st.session_state["library"]),
        )

        with st.expander("üß≠ Revis√£o √©tica (modo formativo)", expanded=st.session_state["ui"]["show_review_mode"]):
            st.write("Use estas perguntas como guia de revis√£o ‚Äî o Veritas n√£o substitui avalia√ß√£o humana.")
            st.markdown(
                "- Os trechos sinalizados t√™m **cita√ß√£o adequada** (direta ou indireta)?\n"
                "- Onde h√° par√°frase, voc√™ **agregou elabora√ß√£o autoral** (argumento, contraste, exemplo, cr√≠tica)?\n"
                "- Trechos metodol√≥gicos est√£o descritos com **especificidade do seu estudo** (e n√£o apenas modelo gen√©rico)?\n"
                "- H√° partes que parecem **bibliografia/recorte t√©cnico** e poderiam ser reorganizadas?\n"
                "- A se√ß√£o de **introdu√ß√£o/fundamenta√ß√£o** est√° dialogando com fontes ou apenas reproduzindo?\n"
            )
            st.caption(ETHICAL_NOTE)

    with col2:
        st.subheader("Resumo")
        st.write("A compara√ß√£o √© feita contra documentos da sua **Biblioteca Veritas**.")

        st.info(
            "Dica: inclua trabalhos anteriores, artigos de refer√™ncia, TCCs, cap√≠tulos, etc. "
            "Quanto melhor a biblioteca, melhor a detec√ß√£o."
        )

        st.markdown("**Observa√ß√£o √©tica:**")
        st.caption(DISCL)
        st.caption(ETHICAL_NOTE)

        st.divider()
        st.markdown("**Sa√∫de do texto (r√°pido):**")
        wc = _safe_words_count(query_text)
        st.write(f"‚Ä¢ Tamanho do texto: **{wc} palavras**")
        if wc and wc < 150:
            st.warning("Texto bem curto pode gerar resultados inst√°veis. Se poss√≠vel, analise se√ß√µes maiores.")

    if run:
        params = st.session_state["params"]
        chunk_words = int(params["chunk_words"])
        stride_words = int(params["stride_words"])
        threshold = float(params["threshold"])
        top_k_per_chunk = int(params.get("top_k_per_chunk", 1))
        exclude_marked = bool(params.get("exclude_marked", True))

        # Filtra biblioteca se usu√°rio marcou documentos como exclu√≠dos
        corpus = {}
        for name, text in st.session_state["library"].items():
            meta = st.session_state["library_meta"].get(name, {})
            if exclude_marked and meta.get("exclude", False):
                continue
            corpus[name] = text

        if not corpus:
            st.error("Todos os documentos da biblioteca est√£o marcados como exclu√≠dos. Ajuste na aba **Biblioteca**.")
        else:
            with st.spinner("Analisando similaridade..."):
                global_sim, matches = compute_matches(
                    query_text=query_text,
                    corpus_docs=corpus,
                    chunk_words=chunk_words,
                    stride_words=stride_words,
                    top_k_per_chunk=top_k_per_chunk,
                    threshold=threshold,
                )

            # Enriquecimento leve (r√≥tulos)
            enriched = []
            for m in (matches or []):
                label = _chunk_type_heuristic(m.query_chunk)
                bib = _likely_bibliographic(m.query_chunk) or _likely_bibliographic(m.source_chunk)
                enriched.append({
                    "source_doc": m.source_doc,
                    "score": m.score,
                    "query_chunk": m.query_chunk,
                    "source_chunk": m.source_chunk,
                    "label": label,
                    "bibliographic_hint": bib,
                })

            st.session_state["last_result"] = {
                "query_name": query_name,
                "global_sim": global_sim,
                "matches": matches,          # original (para highlight_text/report)
                "enriched": enriched,        # para UI
                "params": {
                    "chunk_words": chunk_words,
                    "stride_words": stride_words,
                    "threshold": threshold,
                    "top_k_per_chunk": top_k_per_chunk,
                    "exclude_marked": exclude_marked,
                },
                "query_text": query_text,
                "corpus_size": len(corpus),
            }

    res = st.session_state.get("last_result")
    if res:
        st.divider()
        st.subheader("Resultado")

        global_sim = float(res["global_sim"] or 0.0)
        band_title, band_msg = _band(global_sim)

        c1, c2, c3 = st.columns([0.34, 0.33, 0.33])
        with c1:
            st.metric("√çndice global (estimado)", f"{global_sim*100:.1f}%")
        with c2:
            st.metric("Docs comparados", f"{res.get('corpus_size', 0)}")
        with c3:
            st.metric("Trechos sinalizados", f"{len(res.get('enriched', []) or [])}")

        st.info(f"**{band_title}** ‚Äî {band_msg}")

        if st.session_state["ui"]["show_doc_summary"]:
            with st.expander("üìå Fontes mais presentes no resultado", expanded=True):
                items = _doc_summary(res["matches"])
                if not items:
                    st.write("Nenhuma fonte acima do limiar.")
                else:
                    for doc, avg, n in items[:10]:
                        meta = st.session_state["library_meta"].get(doc, {})
                        tags = meta.get("tags", "")
                        category = meta.get("category", "‚Äî")
                        st.write(f"‚Ä¢ **{doc}** ‚Äî m√©dia **{avg*100:.1f}%** | trechos: **{n}** | categoria: **{category}** | tags: {tags or '‚Äî'}")

        mcol1, mcol2 = st.columns([1, 1], gap="large")

        # ----------------------------
        # Trechos sinalizados (explic√°veis)
        # ----------------------------
        with mcol1:
            st.markdown("### Trechos sinalizados (interpret√°veis)")

            enriched = res.get("enriched", []) or []
            if not enriched:
                st.success("Nenhuma correspond√™ncia acima do limiar foi encontrada.")
            else:
                max_show = int(st.session_state["ui"]["max_matches_show"])
                for i, m in enumerate(enriched[:max_show], start=1):
                    header = f"**{i}.** Fonte: `{m['source_doc']}` ‚Äî **{m['score']*100:.1f}%**"
                    st.markdown(header)

                    if st.session_state["ui"]["show_chunk_labels"]:
                        st.caption(f"Tipo de trecho (heur√≠stica): {m['label']}")
                        if m["bibliographic_hint"]:
                            st.caption("Poss√≠vel trecho bibliogr√°fico/t√©cnico (heur√≠stica). Revise com cuidado, mas sem alarme.")

                    st.caption("Trecho analisado")
                    st.write(m["query_chunk"])
                    st.caption("Trecho fonte")
                    st.write(m["source_chunk"])

                    with st.expander("Perguntas r√°pidas de revis√£o", expanded=False):
                        st.markdown(
                            "- Este trecho precisa de **cita√ß√£o direta/indireta**?\n"
                            "- A **par√°frase** est√° distante o suficiente e com elabora√ß√£o?\n"
                            "- D√° para inserir **coment√°rio autoral** (contraste, justificativa, exemplo)?\n"
                            "- Esse trecho √© **metodologia/defini√ß√£o padr√£o** (onde a similaridade √© comum)?\n"
                        )
                    st.divider()

        # ----------------------------
        # Destaques + Relat√≥rio
        # ----------------------------
        with mcol2:
            st.markdown("### Texto com destaques (melhor esfor√ßo)")
            highlighted = highlight_text(res["query_text"], res["matches"])
            st.text_area("Destaques aparecem entre ‚ü¶ ‚üß", value=highlighted, height=420)

            st.markdown("### Relat√≥rio (PDF)")
            pdf_path = os.path.join(os.getcwd(), f"Relatorio_Veritas_{int(time.time())}.pdf")

            # inclui uma ‚Äúcamada‚Äù interpretativa no disclaimer (sem quebrar o gerador)
            band_title, band_msg = _band(res["global_sim"])
            disclaimer_plus = (
                DISCL
                + "\n\n"
                + ETHICAL_NOTE
                + "\n\n"
                + f"Leitura interpretativa (faixa): {band_title} ‚Äî {band_msg}"
            )

            generate_pdf_report(
                filepath=pdf_path,
                title="Relat√≥rio de An√°lise de Similaridade ‚Äì Veritas",
                query_name=res["query_name"],
                global_similarity=res["global_sim"],
                matches=res["matches"],
                params=res["params"],
                disclaimer=disclaimer_plus,
            )

            with open(pdf_path, "rb") as f:
                st.download_button(
                    "‚¨áÔ∏è Baixar relat√≥rio em PDF",
                    data=f.read(),
                    file_name=os.path.basename(pdf_path),
                    mime="application/pdf",
                    use_container_width=True,
                )


# =========================================================
# TAB 2: Biblioteca
# =========================================================
with tabs[1]:
    st.subheader("Biblioteca Veritas")
    st.write("Os documentos aqui s√£o as **fontes de compara√ß√£o**. Eles ficam salvos na sess√£o (MVP local).")

    up_lib = st.file_uploader(
        "Adicionar documentos √† biblioteca (.docx, .pdf, .txt)",
        type=["docx", "pdf", "txt"],
        accept_multiple_files=True,
    )

    if up_lib:
        added = 0
        for f in up_lib:
            try:
                st.session_state["library"][f.name] = _read_any(f)

                # cria meta padr√£o se n√£o existir
                st.session_state["library_meta"].setdefault(
                    f.name,
                    {"tags": "", "category": "Refer√™ncia", "exclude": False}
                )
                added += 1
            except Exception as e:
                st.error(f"Falha ao ler {f.name}: {e}")

        if added:
            st.success(f"{added} documento(s) adicionados √† biblioteca.")

    st.divider()
    if st.session_state["library"]:
        st.markdown("### Documentos na biblioteca (com tags/categorias)")
        st.caption("Voc√™ pode marcar documentos para **excluir da compara√ß√£o** (ex.: rascunhos, vers√µes repetidas).")

        for name in list(st.session_state["library"].keys()):
            meta = st.session_state["library_meta"].setdefault(
                name, {"tags": "", "category": "Refer√™ncia", "exclude": False}
            )

            with st.container(border=True):
                c1, c2, c3, c4 = st.columns([0.44, 0.24, 0.20, 0.12], vertical_alignment="center")

                with c1:
                    st.write(f"üìÑ **{name}**")
                    st.caption(f"{_safe_words_count(st.session_state['library'][name])} palavras")

                with c2:
                    meta["category"] = st.selectbox(
                        "Categoria",
                        ["Refer√™ncia", "Meu texto (autoria)", "Dom√≠nio p√∫blico", "Modelo/metodologia", "Outros"],
                        index=["Refer√™ncia", "Meu texto (autoria)", "Dom√≠nio p√∫blico", "Modelo/metodologia", "Outros"].index(
                            meta.get("category", "Refer√™ncia") if meta.get("category") in
                            ["Refer√™ncia", "Meu texto (autoria)", "Dom√≠nio p√∫blico", "Modelo/metodologia", "Outros"]
                            else "Refer√™ncia"
                        ),
                        key=f"cat_{name}",
                    )

                with c3:
                    meta["tags"] = st.text_input(
                        "Tags (opcional)",
                        value=meta.get("tags", ""),
                        placeholder="ex.: rogers; fenomenologia; penal; metodologia",
                        key=f"tags_{name}",
                    )
                    meta["exclude"] = st.checkbox(
                        "Excluir da compara√ß√£o",
                        value=bool(meta.get("exclude", False)),
                        key=f"exc_{name}",
                    )

                with c4:
                    if st.button("Remover", key=f"rm_{name}", use_container_width=True):
                        st.session_state["library"].pop(name, None)
                        st.session_state["library_meta"].pop(name, None)
                        st.rerun()

        st.session_state["library_meta"] = st.session_state["library_meta"]
    else:
        st.info("Ainda n√£o h√° documentos na biblioteca.")


# =========================================================
# TAB 3: Configura√ß√µes
# =========================================================
with tabs[2]:
    st.subheader("Configura√ß√µes da an√°lise (MVP)")
    st.write("Ajuste o tamanho dos trechos, limiar e op√ß√µes de visualiza√ß√£o. Em geral, os padr√µes funcionam bem.")

    params = st.session_state["params"]
    ui = st.session_state["ui"]

    st.markdown("### Par√¢metros de detec√ß√£o")
    params["chunk_words"] = st.slider("Tamanho do trecho (palavras)", 30, 140, int(params["chunk_words"]), 5)
    params["stride_words"] = st.slider("Passo entre trechos (palavras)", 10, 80, int(params["stride_words"]), 5)
    params["threshold"] = st.slider("Limiar de sinaliza√ß√£o (0‚Äì1)", 0.50, 0.95, float(params["threshold"]), 0.01)
    params["top_k_per_chunk"] = st.slider("Melhor fonte por trecho (top-k)", 1, 3, int(params.get("top_k_per_chunk", 1)), 1)
    params["exclude_marked"] = st.checkbox("Ignorar docs marcados como exclu√≠dos na biblioteca", value=bool(params.get("exclude_marked", True)))

    st.caption("Sugest√£o: limiar 0,75 √© bom para c√≥pia literal. Para textos com muita par√°frase, reduza para ~0,65.")

    st.divider()
    st.markdown("### Visualiza√ß√£o e modo formativo")
    ui["max_matches_show"] = st.slider("M√°ximo de trechos exibidos", 5, 60, int(ui["max_matches_show"]), 5)
    ui["show_doc_summary"] = st.checkbox("Mostrar resumo por documento (fontes mais presentes)", value=bool(ui["show_doc_summary"]))
    ui["show_chunk_labels"] = st.checkbox("Mostrar r√≥tulos de tipo de trecho (heur√≠stica)", value=bool(ui["show_chunk_labels"]))
    ui["show_review_mode"] = st.checkbox("Manter expander de Revis√£o √©tica aberto por padr√£o", value=bool(ui["show_review_mode"]))

    st.session_state["params"] = params
    st.session_state["ui"] = ui

    st.divider()
    st.markdown("### Nota importante")
    st.caption(
        "Os r√≥tulos (cita√ß√£o/metodologia/conceitual) s√£o heur√≠sticos e servem apenas para orientar leitura. "
        "O Veritas n√£o faz julgamento definitivo sobre pl√°gio."
    )
